{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eaec88e",
   "metadata": {},
   "source": [
    "# Обработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3d7135",
   "metadata": {},
   "source": [
    "Предварительная обработка текстовых данных\n",
    "\n",
    "- преобразование в нижний регистр;\n",
    "- удаление знаков препинания;\n",
    "- удаление стоп-слов;\n",
    "- токенизация корпуса;\n",
    "- стемминг;\n",
    "- лемматизация.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c259fe-da60-4298-bb9d-d9b824ed161e",
   "metadata": {},
   "source": [
    "### Подготовка среды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95f113c-aed1-4ad6-8cba-1bd42d8cb11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!pip install nltk\n",
    "!pip install pymystem3\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aab2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb6796",
   "metadata": {},
   "source": [
    "### Ввод текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e06d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "    Python - это простой в использовании, но мощный в своих возможностях язык программирования. \n",
    "    Он широко используется для веб-разработки, научных вычислений, искусственного интеллекта и многого другого.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b21e76",
   "metadata": {},
   "source": [
    "### Преобразование в нижний регистр"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c80460",
   "metadata": {},
   "source": [
    "Слово с заглавной и строчной буквой для нас одно и то же, но компьютер такие слова воспринимает как разные из-за разного регистра. Чтобы все слова выглядели одинаково, нужно преобразовать их в нижний регистр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be52fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lower = text.lower()\n",
    "print(text_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252da39b",
   "metadata": {},
   "source": [
    "### Удаление знаков препинания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df200fcb",
   "metadata": {},
   "source": [
    "Знаки препинания, такие как точки, запятые, восклицательные знаки и т.д., часто не несут смысловой нагрузки в анализе текста. Поэтому их удаляют, чтобы упростить дальнейшую работу. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e69304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант I. Оставляем только кириллические буквы\n",
    "\n",
    "# Используем регулярное выражение для поиска слов с русскими буквами\n",
    "text_onlyrus = ' '.join(re.findall(r'\\b[а-яА-Я]+\\b', text_lower))\n",
    "print(text_onlyrus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант II. Удаляем знаки препинания и лишние пробелы\n",
    "\n",
    "# Создаем таблицу перевода, заменяющую знаки препинания на пробелы\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "# Применяем таблицу перевода к тексту и удаляем лишние пробелы\n",
    "words = text_lower.translate(translator).split()\n",
    "text_clear = ' '.join(words)\n",
    "print(text_clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa3ad0",
   "metadata": {},
   "source": [
    "### Удаление стоп-слов и токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8ee5c2",
   "metadata": {},
   "source": [
    "Стоп-слова – это часто встречающиеся слова, которые обычно не содержат важной информации для анализа, такие как \"и\", \"в\", \"на\", \"это\" и т.д. Их удаляют, чтобы сосредоточиться на более значимых словах.\n",
    "Токенизация – это процесс разделения текста на отдельные слова или фразы, которые называются токенами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c7c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_set = set(stopwords.words('russian'))\n",
    "print(\"Стоп-слова:\", \", \".join(stop_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32f8225",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [word for word in text_clear.split() if word not in stop_set]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b059a09",
   "metadata": {},
   "source": [
    "### Стемминг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20023a02",
   "metadata": {},
   "source": [
    "Стемминг – это процесс, при котором у слов обрезаются окончания, чтобы привести их к базовой или корневой форме. Это помогает упростить анализ, так как разные формы одного и того же слова будут рассматриваться как одно слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language='russian')\n",
    "tokens_stemm = [stemmer.stem(word) for word in tokens]\n",
    "print(tokens_stemm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403825d6",
   "metadata": {},
   "source": [
    "### Лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a9dbe",
   "metadata": {},
   "source": [
    "Лемматизация похожа на стемминг, но здесь слова преобразуются в их начальную (словарную) форму, называемую леммой. Лемматизация сложнее, чем стемминг, потому что она учитывает грамматические правила и контекст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cea1344",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()\n",
    "tokens_lemma = list(filter(lambda x: x not in [' ', '\\n'], mystem.lemmatize(' '.join(tokens))))\n",
    "print(tokens_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f1e41b",
   "metadata": {},
   "source": [
    "## Дополнительная обработка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd7611",
   "metadata": {},
   "source": [
    "### Перевод текста на другой язык"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1990f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install googletrans==4.0.0-rc1\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d99594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "def translate_text(text, src_language='ru', dest_language='en'):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, src=src_language, dest=dest_language)\n",
    "    return translation.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05934157",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_translate = \"\"\"Привет, как дела? У меня всё хорошо\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781be79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_text = translate_text(text_to_translate)\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ed626d",
   "metadata": {},
   "source": [
    "### Исправление орфографических ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3413bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyaspeller\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyaspeller import YandexSpeller\n",
    "\n",
    "def correct_spelling(text):\n",
    "    speller = YandexSpeller()\n",
    "    corrections = speller.spell(text)\n",
    "    \n",
    "    corrected_text = text\n",
    "    for correction in corrections:\n",
    "        word = correction['word']\n",
    "        suggestions = correction['s']\n",
    "        if suggestions:\n",
    "            corrected_text = corrected_text.replace(word, suggestions[0])\n",
    "    \n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e91ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_with_errors = \"\"\"Превет, как дила? У миня вcе харащо!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71644972",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_text = correct_spelling(text_with_errors)\n",
    "print(f\"Исправленный текст: {corrected_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24822d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
