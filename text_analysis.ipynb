{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "259881a5",
   "metadata": {},
   "source": [
    "# Анализ текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b667e958-ec0f-4d00-891e-8f0035b8c17c",
   "metadata": {},
   "source": [
    "## Морфологический анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f3e91-20e2-4037-87a0-605e8267fd3a",
   "metadata": {},
   "source": [
    "Морфологический анализ текста - это процесс изучения формы или структуры слов.\n",
    "\n",
    "Когда мы говорим о форме слова, мы имеем в виду его части, такие как корень, суффикс, приставка и окончание. \n",
    "\n",
    "Рассмотрим пример:\n",
    "\n",
    "В слове \"бегать\" есть корень \"бег-\", к которому добавляется суффикс \"-ать\". Это делает слово \"бегать\" глаголом, означающим действие бега. Также, если мы добавим приставку \"по-\" и сделаем \"побегать\", это будет означать \"бегать немного\".\n",
    "\n",
    "Теперь рассмотрим окончания. Например, если мы возьмем слово \"бегает\", то его окончание \"-ет\" указывает на то, что это глагол, который описывает действие, выполняемое кем-то или чем-то.\n",
    "\n",
    "Морфологический анализ текста помогает нам понять эти части слова и их значения. Он помогает нам понять, как слова изменяются в разных формах, чтобы передать разные идеи или оттенки значения.\n",
    "\n",
    "Таким образом, морфологический анализ текста помогает нам разбираться в строении слов и их формах, чтобы мы могли лучше понять, что именно хотят нам сказать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fa6ec7-498f-48ff-b4fe-4d5e19708d9a",
   "metadata": {},
   "source": [
    "### Подготовка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eaad3e0-8c13-4da9-b28f-246bf14c151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_import = 'import'\n",
    "os.makedirs(dir_import, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf212f07-5fb0-45fa-9c12-5f302a590bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (0.9.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: pymorphy3 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from pymorphy3) (0.7.2)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from pymorphy3) (2.4.417150.4580142)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (2.4.417127.4579844)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2\n",
    "!pip install pymorphy3\n",
    "!pip install -U pymorphy2-dicts-ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff727f6-de59-4a5f-9fc8-89f492793c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aleksioprime/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pymorphy2\n",
    "import re\n",
    "import string\n",
    "import csv\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11261a-fcd3-4af8-b489-54144b68aa14",
   "metadata": {},
   "source": [
    "### Ввод текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16eb504-be00-42a7-8e25-760ec7a1cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "    Python - это простой в использовании, но мощный в своих возможностях язык программирования. \n",
    "    Он широко используется для веб-разработки, научных вычислений, искусственного интеллекта и многого другого.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db605ba-249f-4676-b25d-8dfa30d63217",
   "metadata": {},
   "source": [
    "### Обработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cea3a85e-db9b-41c2-b514-65620f62123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    stop_set = set(stopwords.words('russian'))\n",
    "    mystem = Mystem()\n",
    "    \n",
    "    words = text.lower().translate(translator).split()\n",
    "    tokens = [word for word in words if word not in stop_set]\n",
    "    # tokens_lemma = list(filter(lambda x: x not in [' ', '\\n'], mystem.lemmatize(' '.join(tokens))))\n",
    "    return tokens\n",
    "\n",
    "tokens_ready = text_processing(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b8e710-4b22-46d8-8847-f56a5234b75b",
   "metadata": {},
   "source": [
    "### Вывод граммем (меток)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e1d9de6-2e68-49aa-900e-20240cdfc57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: ['LATN']\n",
      "это: ['PRCL']\n",
      "простой: ['ADJF', 'Qual femn', 'sing', 'gent']\n",
      "использовании: ['NOUN', 'inan', 'neut sing', 'loct']\n",
      "мощный: ['ADJF', 'Qual masc', 'sing', 'nomn']\n",
      "своих: ['ADJF', 'Apro', 'Anph plur', 'gent']\n",
      "возможностях: ['NOUN', 'inan', 'femn plur', 'loct']\n",
      "язык: ['NOUN', 'inan', 'masc sing', 'accs']\n",
      "программирования: ['NOUN', 'inan', 'neut sing', 'gent']\n",
      "широко: ['ADVB']\n",
      "используется: ['VERB', 'impf', 'intr sing', '3per', 'pres', 'indc']\n",
      "вебразработки: ['NOUN', 'inan', 'femn sing', 'gent']\n",
      "научных: ['ADJF', 'Qual plur', 'gent']\n",
      "вычислений: ['NOUN', 'inan', 'neut plur', 'gent']\n",
      "искусственного: ['ADJF', 'Qual neut', 'sing', 'gent']\n",
      "интеллекта: ['NOUN', 'inan', 'masc sing', 'gent']\n",
      "многого: ['NPRO', 'neut sing', 'gent']\n",
      "другого: ['ADJF', 'Subx', 'Apro neut', 'sing', 'gent']\n"
     ]
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer(lang='ru')\n",
    "for word in tokens_ready:\n",
    "    parsed_word = morph.parse(word)[0]\n",
    "    tags = str(parsed_word.tag).split(',')\n",
    "    print(f\"{word}: {tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ce25fa-1d5c-4f7d-8eb6-ae9e8354a292",
   "metadata": {},
   "source": [
    "### Вывод граммем (расшифровка)\n",
    "https://pymorphy2.readthedocs.io/en/stable/user/grammemes.html#russian-pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91a6bb23-4687-4c5b-abc7-53d4a098a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для загрузки словаря грамем из CSV файла\n",
    "def load_grammemes_dict(csv_file):\n",
    "    grammemes_dict = {}\n",
    "    with open(csv_file, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            internal_id = row['internal_id']\n",
    "            description = row['description']\n",
    "            grammemes_dict[internal_id] = description\n",
    "    return grammemes_dict\n",
    "    \n",
    "# Загрузка словаря грамем из CSV файла\n",
    "import_grammemes = os.path.join(dir_import, \"grammemes.csv\")\n",
    "grammemes_dict = load_grammemes_dict(import_grammemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa9ad7cf-f07c-4d05-835e-5858d5f98cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: ['LATN']\n",
      "это: ['частица']\n",
      "простой: ['имя прилагательное (полное)', 'родительный падеж', 'качественное', 'единственное число', 'женский род']\n",
      "использовании: ['средний род', 'единственное число', 'неодушевлённое', 'имя существительное', 'предложный падеж']\n",
      "мощный: ['именительный падеж', 'имя прилагательное (полное)', 'качественное', 'единственное число', 'мужской род']\n",
      "своих: ['Анафорическое (местоимение)', 'имя прилагательное (полное)', 'родительный падеж', 'местоименное', 'множественное число']\n",
      "возможностях: ['неодушевлённое', 'имя существительное', 'женский род', 'предложный падеж', 'множественное число']\n",
      "язык: ['единственное число', 'неодушевлённое', 'имя существительное', 'винительный падеж', 'мужской род']\n",
      "программирования: ['родительный падеж', 'средний род', 'единственное число', 'неодушевлённое', 'имя существительное']\n",
      "широко: ['наречие']\n",
      "используется: ['непереходный', 'единственное число', 'изъявительное наклонение', 'настоящее время', 'несовершенный вид', 'глагол (личная форма)', '3 лицо']\n",
      "вебразработки: ['родительный падеж', 'единственное число', 'неодушевлённое', 'имя существительное', 'женский род']\n",
      "научных: ['качественное', 'имя прилагательное (полное)', 'родительный падеж', 'множественное число']\n",
      "вычислений: ['родительный падеж', 'средний род', 'неодушевлённое', 'имя существительное', 'множественное число']\n",
      "искусственного: ['имя прилагательное (полное)', 'родительный падеж', 'качественное', 'средний род', 'единственное число']\n",
      "интеллекта: ['родительный падеж', 'единственное число', 'неодушевлённое', 'имя существительное', 'мужской род']\n",
      "многого: ['средний род', 'местоимение-существительное', 'единственное число', 'родительный падеж']\n",
      "другого: ['имя прилагательное (полное)', 'местоименное', 'родительный падеж', 'средний род', 'возможна субстантивация', 'единственное число']\n"
     ]
    }
   ],
   "source": [
    "for word in tokens_ready:\n",
    "    parsed_word = morph.parse(word)[0]\n",
    "    grammemes = parsed_word.tag.grammemes\n",
    "    grammemes_rus = [ grammemes_dict.get(grammeme, grammeme) for grammeme in grammemes ]        \n",
    "    print(f\"{word}: {grammemes_rus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05588d-d34c-4814-bc52-f86715b350eb",
   "metadata": {},
   "source": [
    "### Работа с граммемами\n",
    "\n",
    "- Часть речи можно получить через атрибут POS (```parsed_word.tag.POS```)\n",
    "- Падеж выделяется у существительных, полных прилагательных, полных причастий, числительных и местоимений. Получить его можно через атрибут case (```parsed_word.tag.case```)\n",
    "- Число можно получить через атрибут number (```parsed_word.tag.number```)\n",
    "- Род можно пролучить через атрибут gender (```parsed_word.tag.gender```)\n",
    "\n",
    "### Получение имён существительных и определение из падежа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe356b6b-860b-4e2d-974f-7d4da10f765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "использовании: предложный падеж\n",
      "возможностях: предложный падеж\n",
      "язык: винительный падеж\n",
      "программирования: родительный падеж\n",
      "вебразработки: родительный падеж\n",
      "вычислений: родительный падеж\n",
      "интеллекта: родительный падеж\n"
     ]
    }
   ],
   "source": [
    "for word in tokens_ready:\n",
    "    parsed_word = morph.parse(word)[0]\n",
    "    if parsed_word.tag.POS == 'NOUN':\n",
    "        case = parsed_word.tag.case\n",
    "        print(f\"{word}: {grammemes_dict.get(case, case)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ce91bd-9cdb-49f7-8187-251b0b343a3c",
   "metadata": {},
   "source": [
    "### Склонение слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08c3303f-a4b3-4e63-a870-7fb33b7438cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кошка: nomn, sing (именительный падеж, единственное число)\n",
      "кошки: gent, sing (родительный падеж, единственное число)\n",
      "кошке: datv, sing (дательный падеж, единственное число)\n",
      "кошку: accs, sing (винительный падеж, единственное число)\n",
      "кошкой: ablt, sing (творительный падеж, единственное число)\n",
      "кошкою: ablt, sing (творительный падеж, единственное число)\n",
      "кошке: loct, sing (предложный падеж, единственное число)\n",
      "кошки: nomn, plur (именительный падеж, множественное число)\n",
      "кошек: gent, plur (родительный падеж, множественное число)\n",
      "кошкам: datv, plur (дательный падеж, множественное число)\n",
      "кошек: accs, plur (винительный падеж, множественное число)\n",
      "кошками: ablt, plur (творительный падеж, множественное число)\n",
      "кошках: loct, plur (предложный падеж, множественное число)\n"
     ]
    }
   ],
   "source": [
    "word = 'кошка'\n",
    "my_word = morph.parse(word)[0]\n",
    "\n",
    "for word in my_word.lexeme:\n",
    "    case = word.tag.case\n",
    "    case_rus = grammemes_dict.get(case, case)\n",
    "    number = word.tag.number\n",
    "    number_rus = grammemes_dict.get(number, number)\n",
    "    print(f\"{word.word}: {case}, {number} ({case_rus}, {number_rus})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c55795-a120-4833-a9d0-c4f86a0b7d9a",
   "metadata": {},
   "source": [
    "### Склонение слова с числительным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4d95ece-926d-4726-8c9f-8e67b1f9f66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 кошек\n",
      "1 кошка\n",
      "2 кошки\n",
      "3 кошки\n",
      "4 кошки\n",
      "5 кошек\n",
      "6 кошек\n",
      "7 кошек\n"
     ]
    }
   ],
   "source": [
    "word = 'кошка'\n",
    "my_word = morph.parse(word)[0]\n",
    "\n",
    "for i in range(8):\n",
    "    word_i = my_word.make_agree_with_number(i).word\n",
    "    print(f\"{i} {word_i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938db0a4-e3ba-4245-8587-efe7de365220",
   "metadata": {},
   "source": [
    "## Синтаксический анализ текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d24eaf-760f-4f30-b1bf-bc1cf7d42496",
   "metadata": {},
   "source": [
    "Синтаксический анализ текста - это процесс, в ходе которого мы изучаем, как слова в предложении связаны между собой.\n",
    "\n",
    "Когда мы говорим или пишем, мы используем слова, чтобы передать свои мысли и идеи. Эти слова не просто располагаются одно за другим, они также имеют определенные отношения между собой. Например, в предложении \"Кот ловит мышь\", слово \"кот\" выполняет действие, а слово \"мышь\" является объектом этого действия.\n",
    "\n",
    "Синтаксический анализ текста помогает нам понять эти отношения между словами. Он помогает нам определить, какие слова являются частью предложения, какие слова выполняют действие, какие слова описывают субъект или объект, и как эти слова связаны друг с другом.\n",
    "\n",
    "В результате синтаксического анализа мы можем построить дерево, которое показывает, как каждое слово в предложении связано с другими словами. Это дерево называется деревом зависимостей. Оно помогает нам лучше понять структуру предложения и какие идеи или действия оно передает.\n",
    "\n",
    "Примеры ролей в дереве:\n",
    "\n",
    "- **nsubj**: Субъект (Subject) - подлежащее предложения. Это слово или фраза, которая выполняет действие, описанное глаголом. Например, в предложении \"Кот ловит мышь\", \"кот\" является подлежащим.\n",
    "\n",
    "- **root**: Корень (Root) - это корневой токен зависимостей. Он не имеет родителя и является центральным токеном зависимостей в дереве. Обычно это глагол или главный глагольный комплекс в предложении.\n",
    "\n",
    "- **advmod**: Наречие (Adverbial Modifier) - это наречие, которое модифицирует глагол, прилагательное, другое наречие или даже целое предложение. Оно обычно указывает на время, место, причину, степень или образ выполнения действия. Например, в предложении \"Он очень быстро бегает\", \"очень\" - наречие, модифицирующее глагол \"бегает\".\n",
    "\n",
    "- **obl**: Объект (Object) - это комплемент, который связан с глаголом и обозначает объект действия. Например, в предложении \"Она купила новый автомобиль\", \"новый автомобиль\" - объект.\n",
    "\n",
    "- **dobj**: Прямой объект (Direct Object) - подкатегория объекта, который является прямым объектом действия.\n",
    "\n",
    "- **attr**: Атрибут (Attribute) - это слово, которое указывает на свойство или характеристику субъекта.\n",
    "\n",
    "- **subj**: Подлежащее (Subject) - альтернативное обозначение для подлежащего.\n",
    "\n",
    "- **aux**: Вспомогательный глагол (Auxiliary) - это вспомогательный глагол, который используется для образования глагольной формы, но сам не несет основного смысла.\n",
    "\n",
    "- **conj**: Сочинение (Conjunct) - это токен, который является частью координации, например, в списке или параллельном выражении."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdf8a74-107c-4344-9e02-16404cf329ff",
   "metadata": {},
   "source": [
    "### Установка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "597d36ec-717e-40b3-b06e-5ac3c13671bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: spacy in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (2.7.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
      "Collecting stanza\n",
      "  Downloading stanza-1.8.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting emoji (from stanza)\n",
      "  Downloading emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from stanza) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from stanza) (5.27.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from stanza) (2.32.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from stanza) (3.2.1)\n",
      "Collecting toml (from stanza)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: torch>=1.3.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from stanza) (2.3.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from stanza) (4.66.4)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from torch>=1.3.0->stanza) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from torch>=1.3.0->stanza) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from torch>=1.3.0->stanza) (1.12.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from torch>=1.3.0->stanza) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from torch>=1.3.0->stanza) (2024.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from requests->stanza) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from requests->stanza) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from requests->stanza) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from requests->stanza) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from jinja2->torch>=1.3.0->stanza) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n",
      "Downloading stanza-1.8.2-py3-none-any.whl (990 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.1/990.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Installing collected packages: toml, emoji, stanza\n",
      "Successfully installed emoji-2.12.1 stanza-1.8.2 toml-0.10.2\n",
      "Collecting ru-core-news-lg==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_lg-3.7.0/ru_core_news_lg-3.7.0-py3-none-any.whl (513.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m513.4/513.4 MB\u001b[0m \u001b[31m981.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from ru-core-news-lg==3.7.0) (3.7.4)\n",
      "Requirement already satisfied: pymorphy3>=1.0.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from ru-core-news-lg==3.7.0) (2.0.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.7.0) (0.7.2)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.7.0) (2.4.417150.4580142)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.7.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.18.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ru_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install spacy\n",
    "!python -m spacy download ru_core_news_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bd381b-b88a-452e-b130-fa03ae2c11cb",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18064a-f7bc-4e38-85a6-8b452ff66ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем библиотеку spaCy для обработки естественного языка\n",
    "import spacy\n",
    "# Импортируем модуль displacy из spaCy для визуализации зависимостей\n",
    "from spacy import displacy\n",
    "# Импортируем русский языковой модельный пакет большого размера\n",
    "import ru_core_news_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93524b0-84f4-4f1b-9669-a1137bb010aa",
   "metadata": {},
   "source": [
    "### Ввод текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7e9f720-90cd-4868-8c4a-ee73e3e58c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Я пришел домой поздно вечером.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309df11a-4eb5-4616-8f5d-0c62b6de7df1",
   "metadata": {},
   "source": [
    "### Построение графика синтаксических зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f458df0-6826-4a0a-b190-9a2e045a50ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"ru\" id=\"cc2fe91431594d58b712c7a88d04ca11-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Я</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">пришел</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">домой</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">поздно</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">вечером.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cc2fe91431594d58b712c7a88d04ca11-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cc2fe91431594d58b712c7a88d04ca11-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cc2fe91431594d58b712c7a88d04ca11-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cc2fe91431594d58b712c7a88d04ca11-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cc2fe91431594d58b712c7a88d04ca11-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cc2fe91431594d58b712c7a88d04ca11-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cc2fe91431594d58b712c7a88d04ca11-0-3\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cc2fe91431594d58b712c7a88d04ca11-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загружаем русскую языковую модель большого размера\n",
    "ru_nlp = ru_core_news_lg.load()\n",
    "# Применяем модель к тексту, создавая объект Doc\n",
    "doc = ru_nlp(text)\n",
    "# Визуализируем синтаксические зависимости в тексте\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2823848b-c74a-4dd4-99b4-0eefc6afa261",
   "metadata": {},
   "source": [
    "## Семантический анализ текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde8fd95-5291-45aa-a1be-1003710e5ac4",
   "metadata": {},
   "source": [
    "Семантический анализ текста - это способ понимания значения слов и их связей в предложении или тексте. \n",
    "\n",
    "Когда мы читаем или слушаем текст, мы не просто видим отдельные слова, но и стараемся понять, о чем идет речь, какие мысли автор хочет передать. Семантический анализ помогает нам в этом.\n",
    "\n",
    "Для понимания смысла текста нам нужно знать значения слов и как они сочетаются друг с другом. Например, если мы видим слова \"кот\" и \"мышь\", мы понимаем, что кот может поймать мышь, потому что это типичное поведение котов. Это понимание значений слов и их связей - это и есть семантический анализ.\n",
    "\n",
    "Семантический анализ также помогает нам понять отношения между предложениями или частями текста. Например, если в одном предложении говорится \"Кот поймал мышь\", а в другом \"Мышь попыталась убежать\", мы понимаем, что первое предложение описывает действие, которое произошло до второго.\n",
    "\n",
    "Таким образом, семантический анализ текста помогает нам не просто читать слова, а понимать, о чем речь и какие мысли или идеи автор хочет передать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a8c75-8e43-4ac4-86c6-cea3ef504674",
   "metadata": {},
   "source": [
    "### Установка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61aaf21f-34db-46d5-a59a-55e77fffa8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dostoevsky in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (0.6.0)\n",
      "Requirement already satisfied: fasttext==0.9.2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from dostoevsky) (0.9.2)\n",
      "Requirement already satisfied: razdel==0.5.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from dostoevsky) (0.5.0)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from fasttext==0.9.2->dostoevsky) (2.10.3)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from fasttext==0.9.2->dostoevsky) (69.5.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/analyze/lib/python3.9/site-packages (from fasttext==0.9.2->dostoevsky) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!pip install spacy\n",
    "!python -m spacy download ru_core_news_lg\n",
    "!pip install dostoevsky\n",
    "!python3 -m dostoevsky download fasttext-social-network-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2eae1f-99c8-4618-b1e0-4d7b30c6fb68",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe389b10-2c3f-4681-80b7-709367a832e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk import Tree\n",
    "from spacy import displacy\n",
    "import ru_core_news_lg\n",
    "\n",
    "from dostoevsky.tokenization import RegexTokenizer\n",
    "from dostoevsky.models import FastTextSocialNetworkModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4ac718-221e-4ef4-8fe5-baee99a66e0c",
   "metadata": {},
   "source": [
    "### Ввод текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8d672c1-389c-4112-9707-bef95d37e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Ну ты и урод\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c70525-7d7d-424b-92c3-e0c558761c7c",
   "metadata": {},
   "source": [
    "### Извлечение именованных сущностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0990072-b188-46e0-831e-c27acf4ffdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Джон: PER (Named person or family.)\n",
      "Волгу: LOC (Non-GPE locations, mountain ranges, bodies of water)\n"
     ]
    }
   ],
   "source": [
    "en_nlp = ru_core_news_lg.load()\n",
    "doc = en_nlp(text)\n",
    "for named_entity in doc.ents:\n",
    "    label = named_entity.label_\n",
    "    explain_label = spacy.explain(label)\n",
    "    print(f\"{named_entity}: {label} ({explain_label})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d8e0a-1a6c-4dcd-b709-940e826c071d",
   "metadata": {},
   "source": [
    "### Анализ тональности\n",
    "https://github.com/bureaucratic-labs/dostoevsky/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2b84088-c759-4168-b83a-7ae1cee2863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative: 0.6654205918312073\n",
      "neutral: 0.348655104637146\n",
      "positive: 0.020974241197109222\n",
      "skip: 0.005564924795180559\n",
      "speech: 1.0000003385357559e-05\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexTokenizer()\n",
    "model = FastTextSocialNetworkModel(tokenizer=tokenizer)\n",
    "\n",
    "results = model.predict([text], k=5)[0]\n",
    "print(\"\\n\".join([f\"{key}: {value}\" for key, value in results.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c971ce-58cf-4554-99e8-c36f610f5d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
