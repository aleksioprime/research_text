{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2550ef8f-e951-4590-b261-bc8177b04d66",
   "metadata": {},
   "source": [
    "# Проектная работа"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33677314-94e1-4c30-96a6-3bbf68e7cfc8",
   "metadata": {},
   "source": [
    "## Загрузка и обработка текстовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13048181-d795-42c3-bddf-cd72e2155b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_export = 'export'\n",
    "os.makedirs(dir_export, exist_ok=True)\n",
    "\n",
    "dir_import = 'import'\n",
    "os.makedirs(dir_import, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6168689e-e3c1-4ffb-8498-54666210dd75",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da8d3cd-6ed8-4382-a655-b858304b2082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9743567d-5f69-4c53-8b9b-391a79b4e6d8",
   "metadata": {},
   "source": [
    "### Чтение текстовых данных в групппированный словарь сообщений\n",
    "\n",
    "```\n",
    "[\n",
    "  'id пользователя',\n",
    "  [\n",
    "    {\n",
    "      'text': Текст сообщения,\n",
    "      'date': Дата сообщения\n",
    "    },\n",
    "      ...\n",
    "  ]\n",
    "  ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac9a12-f27b-4c01-be0b-7d97d193e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_group_messages_by_user(csv_filename):\n",
    "    user_messages = defaultdict(list)\n",
    "    user_name = dict()\n",
    "\n",
    "    with open(csv_filename, mode='r', encoding='utf-8') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        for row in csv_reader:\n",
    "            user_id = row['user_id']\n",
    "            message = row['message']\n",
    "            # Преобразование строки в объект datetime\n",
    "            date = datetime.fromisoformat(row['date']).strftime('%d.%m.%Y %H:%M:%S')\n",
    "            user_messages[user_id].append({\n",
    "                'text': message,\n",
    "                'date': date,\n",
    "            })\n",
    "            user_name[user_id] = {\n",
    "                'username': row['username'],\n",
    "                'fullname': row['fullname'],\n",
    "            }\n",
    "    \n",
    "    return user_messages, user_name\n",
    "    \n",
    "messages_filename = os.path.join(dir_import, \"messages.csv\")\n",
    "grouped_messages, users = read_and_group_messages_by_user(messages_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f1c04-8e1f-4707-ae11-42f83331ef76",
   "metadata": {},
   "source": [
    "### Вывод ID пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6792f7b0-3b39-441a-bdf0-29c089081188",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id in grouped_messages.keys():\n",
    "    print(f\"{user_id}:\\t@{users[user_id]['username'] or '-'} ({users[user_id]['fullname'] or '-'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d975d5d6-04aa-47e6-803d-a69e388a968d",
   "metadata": {},
   "source": [
    "### Выбор пользователя для тестов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6afcef2-7189-4058-ab1f-a1ef92023aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = '536537422'\n",
    "user = f\"@{users[user_id]['username'] or '-'} ({users[user_id]['fullname'] or '-'})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d747261b-7345-4985-9b7e-61554dfd66df",
   "metadata": {},
   "source": [
    "### Вывод всех сообщений пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ddae78-2c0d-4f3d-822d-410cc23923d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Сообщения от пользователя ID {user_id} ({user}): \")\n",
    "for message in grouped_messages[user_id]:\n",
    "    print(f\" - {message['date']} {message['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bf5979-c765-41bb-a46c-ed8a42bf4d13",
   "metadata": {},
   "source": [
    "### Обработка текста\n",
    "\n",
    "```\n",
    "[\n",
    "  'id пользователя',\n",
    "  [\n",
    "    {\n",
    "      'text': Текст сообщения,\n",
    "      'date': Дата сообщения,\n",
    "      'tokens': Обработанный текст\n",
    "    },\n",
    "      ...\n",
    "  ]\n",
    "  ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5145f-22cb-4ef6-90d9-49e3684d2004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    stop_set = set(stopwords.words('russian'))\n",
    "    mystem = Mystem()\n",
    "    \n",
    "    words = text.lower().translate(translator).split()\n",
    "    words_onlyrus = re.findall(r'\\b[а-яА-Я]+\\b', text.lower())\n",
    "    tokens = list(filter(lambda x: x not in {' ', '\\n'} | stop_set, words_onlyrus))\n",
    "    # tokens = mystem.lemmatize(' '.join(tokens))\n",
    "    return tokens\n",
    "\n",
    "for user_messages in grouped_messages.values():\n",
    "    print(f'Обработка сообщений пользователя {user_id}:')\n",
    "    for message in tqdm(user_messages):\n",
    "        message['tokens'] = text_processing(message['text'])\n",
    "\n",
    "print(f\"Сообщения от пользователя ID {user_id} ({user}): \")\n",
    "for message in grouped_messages[user_id]:\n",
    "    print(f\" - {message['date']} {message['tokens']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521cb7b2-4f51-4334-9b06-953f1d2d3db5",
   "metadata": {},
   "source": [
    "### Объединение всех сообщений каждого пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d32c869-cc73-42b8-bc23-99fead62dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_all_messages = {}\n",
    "for user, user_messages in grouped_messages.items():\n",
    "    user_all_messages[user] = \" \".join([\" \".join(msg['tokens']) for msg in user_messages])\n",
    "\n",
    "print(f\"Текст сообщений от пользователя ID {user_id} ({user}): \")\n",
    "print(user_all_messages[user_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a498e3d-c5fd-4c54-af78-95f62ab0542b",
   "metadata": {},
   "source": [
    "## Частота вхождения слов в текст"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c5e30d-3e96-46ff-b39f-78df7e6e8f31",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6ebd2-9d0d-47e4-85cb-df932d9f8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from IPython.display import display, HTML\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43d588b-85b6-4b36-a102-3897d10c02c5",
   "metadata": {},
   "source": [
    "### Выбор пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a160ec-a273-41e8-81e5-2889a7efbf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = '536537422'\n",
    "user = f\"@{users[user_id]['username'] or '-'} ({users[user_id]['fullname'] or '-'})\"\n",
    "text_user = user_all_messages[user_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01748c39-7cf7-46f5-be5c-6886f36f62cc",
   "metadata": {},
   "source": [
    "### Нахождение количества слов в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38287aec-b4e3-4a8f-a345-c71a11f55678",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(text_user)\n",
    "items = blob.word_counts.items()\n",
    "sorted_items = sorted(items, key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af6b122-cfad-46d2-9cef-6f2e3ac38e79",
   "metadata": {},
   "source": [
    "### Вывод частоты слов в тексте в виде таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd6682-1e3a-4459-81d9-4c58744591b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sorted_items, columns=['word', 'count'])\n",
    "export_xlsx = os.path.join(dir_export, f\"words-{user_id}.xlsx\")\n",
    "df.to_excel(export_xlsx)\n",
    "print(f\"Таблица частоты слов пользователя с ID {user_id} ({user}): \")\n",
    "display(HTML(df.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d807ba-1049-47cf-95b2-f8c217f780a2",
   "metadata": {},
   "source": [
    "### Вывод частоты слов в тексте в виде гистограммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b29a457-50b1-430c-a9d6-9f740a907576",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = df[:10].plot.bar(x='word', y='count', legend=False)\n",
    "# Добавление заголовка и меток осей\n",
    "axes.set_title('Частота слов', fontsize=16)\n",
    "axes.set_xlabel('Слова', fontsize=14)\n",
    "axes.set_ylabel('Количество', fontsize=14)\n",
    "# Сохранение диаграммы\n",
    "export_plt = os.path.join(dir_export, f\"words-{user_id}.png\")\n",
    "plt.savefig(export_plt)\n",
    "# Вывод диаграммы на экран\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0598262b-cf8b-4957-a65c-686a272057f2",
   "metadata": {},
   "source": [
    "### Создание словарного облака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663c0c6-cd9d-4d90-afcc-096cb174282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание объекта WordCloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white')\n",
    "wordcloud = wordcloud.generate(list(user_all_messages.values())[1])\n",
    "\n",
    "# Отображение облака слов\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287234c4-f736-4bec-aaee-d761e161fdb3",
   "metadata": {},
   "source": [
    "## Анализ тональности текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f3827a-1b44-4bc1-9084-627d86f90d15",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193ba0b4-5b9f-48e9-9e62-b202d3e4280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import pipeline\n",
    "\n",
    "import spacy\n",
    "from nltk import Tree\n",
    "from spacy import displacy\n",
    "import ru_core_news_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a56b855-4c14-4838-a3e8-778cf108f134",
   "metadata": {},
   "source": [
    "### Составление набора топ-100 слов пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a46b7e-2242-45cd-9670-b724d1a82273",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = \" \".join(list(map(lambda x: x[0], sorted_items))[:100])\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147c05d7-4d7d-4cde-8fc5-092af9f3e8ae",
   "metadata": {},
   "source": [
    "### Анализ тональности\n",
    "https://huggingface.co/blanchefort/rubert-base-cased-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d5957-0e79-4e0d-9811-b1b4e9929b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment', return_dict=True)\n",
    "labels = ['Нейтральный', 'Позитивный', 'Негативный']\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    return predicted\n",
    "\n",
    "probabilities = predict(top_words)\n",
    "for label, prob in zip(labels, probabilities[0]):\n",
    "    print(f\"{label}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e83eae2-d6ce-4fa7-b788-4a8aa685b79e",
   "metadata": {},
   "source": [
    "### Анализ токсичности\n",
    "https://huggingface.co/IlyaGusev/rubertconv_toxic_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bbef1f-65c5-4bbb-a03f-24c19e8df796",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"IlyaGusev/rubertconv_toxic_clf\"\n",
    "pipe = pipeline(\"text-classification\", model=model_name, tokenizer=model_name, framework=\"pt\") \n",
    "pipe([top_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5004a084-8f02-4d7e-a989-772aa86204b6",
   "metadata": {},
   "source": [
    "## Дополнительные задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de59ce65-89da-4913-970c-7adb245ee233",
   "metadata": {},
   "source": [
    "Другие модели для анализа текста можно посмотреть на сайте:\n",
    "https://huggingface.co/models?pipeline_tag=text-classification&language=ru&sort=trending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e48d8-9846-415f-ae2c-a0961f11eeab",
   "metadata": {},
   "source": [
    "### Текст для тестов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f624b765-2a6b-436d-b23f-b2902913b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_text = os.path.join(dir_import, \"new.txt\")\n",
    "with open(import_text, 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68fb701-9476-4e05-b4d5-60206af3e22d",
   "metadata": {},
   "source": [
    "### Резюме статьи\n",
    "https://huggingface.co/utrobinmv/t5_summary_en_ru_zh_base_2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81015e45-cc28-4a4c-882d-21a2e01d51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model_name = 'utrobinmv/t5_summary_en_ru_zh_base_2048'\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "prefix = 'summary: '\n",
    "src_text = prefix + content\n",
    "input_ids = tokenizer(src_text, return_tensors=\"pt\")\n",
    "\n",
    "generated_tokens = model.generate(**input_ids)\n",
    "\n",
    "result = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "print(result)\n",
    "\n",
    "# text brief summary generate\n",
    "prefix = 'summary brief: '\n",
    "src_text = prefix + content\n",
    "input_ids = tokenizer(src_text, return_tensors=\"pt\")\n",
    "\n",
    "generated_tokens = model.generate(**input_ids)\n",
    "\n",
    "result = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "print(result)\n",
    "\n",
    "# text big summary generate\n",
    "prefix = 'summary big: '\n",
    "src_text = prefix + content\n",
    "input_ids = tokenizer(src_text, return_tensors=\"pt\")\n",
    "\n",
    "generated_tokens = model.generate(**input_ids)\n",
    "\n",
    "result = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eecf47-0f86-4ac5-88f9-8a398f52e460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
